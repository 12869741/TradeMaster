{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Hyperparameter Tuning for DeepScalper\n",
    "This tutorial shows how automatic hyperparameter tuning is conducted with Optuna library.\n",
    "## Step 1: Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "ROOT = str(Path(\"auto_tuning.ipynb\").resolve().parents[1])\n",
    "sys.path.append(ROOT)\n",
    "\n",
    "import torch\n",
    "import argparse\n",
    "import os.path as osp\n",
    "from mmcv import Config\n",
    "from trademaster.utils import replace_cfg_vals\n",
    "from trademaster.nets.builder import build_net\n",
    "from trademaster.environments.builder import build_environment\n",
    "from trademaster.datasets.builder import build_dataset\n",
    "from trademaster.agents.builder import build_agent\n",
    "from trademaster.optimizers.builder import build_optimizer\n",
    "from trademaster.losses.builder import build_loss\n",
    "from trademaster.trainers.builder import build_trainer\n",
    "from trademaster.transition.builder import build_transition\n",
    "import pdb\n",
    "import optuna\n",
    "from shutil import copyfile\n",
    "import joblib\n",
    "from trademaster.utils import set_seed\n",
    "set_seed(2023)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Configs\n",
    "Load default config from the folder configs/algorithmic_trading/algorithmic_trading_BTC_dqn_dqn_adam_mse.py\n",
    "Set the flag auto_tuning to True and n_trials as the number of hyperparameter groups wanted to be searched. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Download Alpaca Datasets')\n",
    "    parser.add_argument(\"--config\", default=osp.join(ROOT, \"configs\", \"algorithmic_trading\", \"algorithmic_trading_BTC_dqn_dqn_adam_mse.py\"),\n",
    "                        help=\"download datasets config file path\")\n",
    "    parser.add_argument(\"--task_name\", type=str, default=\"train\")\n",
    "    parser.add_argument(\"--test_style\", type=str, default='-1')\n",
    "    parser.add_argument(\"--auto_tuning\", default=False, type=bool)\n",
    "    parser.add_argument(\"--n_trials\", default=10, type=int)\n",
    "    args = parser.parse_args([])\n",
    "    return args"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build RL agent, environment and trainer\n",
    "Build the environment of algorithmic trading, agent and trainer of DeepScalper following the previous tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dqn_builder(args, sampled_params):\n",
    "    cfg = Config.fromfile(args.config)\n",
    "    task_name = args.task_name\n",
    "    cfg = replace_cfg_vals(cfg)\n",
    "    cfg.data.update({'test_style': args.test_style})\n",
    "    \n",
    "    dataset = build_dataset(cfg)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    train_environment = build_environment(cfg, default_args=dict(dataset=dataset, task=\"train\"))\n",
    "    valid_environment = build_environment(cfg, default_args=dict(dataset=dataset, task=\"valid\"))\n",
    "    test_environment = build_environment(cfg, default_args=dict(dataset=dataset, task=\"test\"))\n",
    "\n",
    "    if task_name.startswith(\"style_test\"):\n",
    "        test_style_environments = []\n",
    "        for i, path in enumerate(dataset.test_style_paths):\n",
    "            test_style_environments.append(build_environment(cfg, default_args=dict(dataset=dataset, task=\"test_style\",\n",
    "                                                                                    style_test_path=path,\n",
    "                                                                                    task_index=i)))\n",
    "\n",
    "    action_dim = train_environment.action_dim\n",
    "    state_dim = train_environment.state_dim\n",
    "\n",
    "    cfg.act.update(dict(action_dim=action_dim, state_dim=state_dim))\n",
    "\n",
    "    # hyperparameters sampled from sampler \n",
    "    if args.auto_tuning == True:\n",
    "        lr = sampled_params['lr']\n",
    "        explore_rate = sampled_params['explore_rate']\n",
    "        dims = sampled_params['dims']\n",
    "        cfg.optimizer.update(dict(lr=lr))\n",
    "        cfg.act.update(dict(explore_rate=explore_rate, dims = dims))\n",
    "\n",
    "    print(cfg)\n",
    "\n",
    "    act = build_net(cfg.act)\n",
    "    act_optimizer = build_optimizer(cfg, default_args=dict(params=act.parameters()))\n",
    "\n",
    "    if cfg.cri:\n",
    "        cfg.cri.update(dict(action_dim=action_dim, state_dim=state_dim))\n",
    "        cri_net = build_net(cfg.cri)\n",
    "        cri_optimizer = build_optimizer(cfg, default_args=dict(params=cri.parameters()))\n",
    "    else:\n",
    "        cri = None\n",
    "        cri_optimizer = None\n",
    "\n",
    "    if_remove = cfg.trainer.if_remove\n",
    "    work_dir = os.path.join(ROOT, cfg.work_dir)\n",
    "    \n",
    "\n",
    "    if not os.path.exists(work_dir):\n",
    "        os.makedirs(work_dir)\n",
    "    \n",
    "    cfg.dump(osp.join(ROOT, cfg.work_dir, osp.basename(args.config)))\n",
    "\n",
    "\n",
    "    criterion = build_loss(cfg)\n",
    "\n",
    "    transition = build_transition(cfg)\n",
    "\n",
    "    agent = build_agent(cfg, default_args=dict(action_dim = action_dim,\n",
    "                                               state_dim = state_dim,\n",
    "                                               act = act,\n",
    "                                               cri = cri,\n",
    "                                               act_optimizer = act_optimizer,\n",
    "                                               cri_optimizer = cri_optimizer,\n",
    "                                               criterion = criterion,\n",
    "                                               transition = transition,\n",
    "                                               device = device))\n",
    "\n",
    "    if task_name.startswith(\"style_test\"):\n",
    "        trainers = []\n",
    "        for env in test_style_environments:\n",
    "            trainers.append(build_trainer(cfg, default_args=dict(train_environment=train_environment,\n",
    "                                                                 valid_environment=valid_environment,\n",
    "                                                                 test_environment=env,\n",
    "                                                                 agent=agent,\n",
    "                                                                 device=device)))\n",
    "    else:\n",
    "        trainer = build_trainer(cfg, default_args=dict(train_environment = train_environment,\n",
    "                                                   valid_environment = valid_environment,\n",
    "                                                   test_environment = test_environment,\n",
    "                                                   agent = agent,\n",
    "                                                   device = device))\n",
    "\n",
    "    if task_name.startswith(\"style_test\"):\n",
    "        return trainers\n",
    "    else:\n",
    "        return trainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Sample hyperparameters using Optuna\n",
    "Optuna library provides functions to sample different types of hyperparameters. In this tutorial, learning rate, explore rate, number of hidden nodes of DQN are tuned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_params(trial: optuna.Trial):\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-3, log=True)\n",
    "    explore_rate = trial.suggest_float(\"explore_rate\", 0.15, 0.3, step=0.05)\n",
    "    dims = trial.suggest_categorical(\"hidden_nodes\", [(64,32), (128,64)])\n",
    "    trial_number = trial.number\n",
    "    sampled_params = dict(lr=lr, explore_rate=explore_rate, dims=dims, trial_number=trial_number)\n",
    "    return sampled_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Define objective function of the optimization procedure\n",
    "Optuna tries to find the best hyperparameter pair by optimizing a specific objective function. \n",
    "In this tutorial, the original training procedure is repeated, and the sum of episode reward on valid dataset is used as the objective function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    args = parse_args()\n",
    "    sampled_params = sample_params(trial)\n",
    "    trainer = test_dqn_builder(args, sampled_params)\n",
    "    valid_score = trainer.train_and_valid_trial(sampled_params['trial_number'])\n",
    "    return valid_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run the whole tuning procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-24 03:37:30,152]\u001b[0m A new study created in memory with name: no-name-5ea2c03e-02bc-424b-a593-95ac03f081f0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config (path: /home/cqzong/TradeMaster/configs/algorithmic_trading/algorithmic_trading_BTC_dqn_dqn_adam_mse.py): {'data': {'type': 'AlgorithmicTradingDataset', 'data_path': 'data/algorithmic_trading/BTC', 'train_path': 'data/algorithmic_trading/BTC/train.csv', 'valid_path': 'data/algorithmic_trading/BTC/valid.csv', 'test_path': 'data/algorithmic_trading/BTC/test.csv', 'test_dynamic_path': 'data/algorithmic_trading/BTC/test_labeled_3_24_-0.15_0.15.csv', 'tech_indicator_list': ['high', 'low', 'open', 'close', 'adjcp', 'zopen', 'zhigh', 'zlow', 'zadjcp', 'zclose', 'zd_5', 'zd_10', 'zd_15', 'zd_20', 'zd_25', 'zd_30'], 'backward_num_day': 5, 'forward_num_day': 5, 'test_dynamic': '-1', 'test_style': '-1'}, 'environment': {'type': 'AlgorithmicTradingEnvironment'}, 'agent': {'type': 'AlgorithmicTradingDQN', 'max_step': 12345, 'reward_scale': 1, 'repeat_times': 1, 'gamma': 0.9, 'batch_size': 64, 'clip_grad_norm': 3.0, 'soft_update_tau': 0, 'state_value_tau': 0.005}, 'trainer': {'type': 'AlgorithmicTradingTrainer', 'epochs': 20, 'work_dir': 'work_dir/algorithmic_trading_BTC_dqn_dqn_adam_mse', 'seeds_list': (12345,), 'batch_size': 64, 'horizon_len': 1024, 'buffer_size': 1000000.0, 'num_threads': 8, 'if_remove': False, 'if_discrete': True, 'if_off_policy': True, 'if_keep_save': True, 'if_over_write': False, 'if_save_buffer': False}, 'loss': {'type': 'MSELoss'}, 'optimizer': {'type': 'Adam', 'lr': 0.001}, 'act': {'type': 'QNet', 'state_dim': 82, 'action_dim': 3, 'dims': (64, 32), 'explore_rate': 0.25}, 'cri': None, 'transition': {'type': 'Transition'}, 'task_name': 'algorithmic_trading', 'dataset_name': 'BTC', 'optimizer_name': 'adam', 'loss_name': 'mse', 'net_name': 'dqn', 'agent_name': 'dqn', 'work_dir': 'work_dir/algorithmic_trading_BTC_dqn_dqn_adam_mse', 'batch_size': 64}\n",
      "| Arguments Keep work_dir: /home/cqzong/TradeMaster/work_dir/algorithmic_trading_BTC_dqn_dqn_adam_mse\n",
      "Train Episode: [1/20]\n",
      "+---------------+---------------------+---------------+-------------+-------------+--------------+---------------+---------------+\n",
      "| Profit Margin | Buy and Hold Profit | Excess Profit | Sharp Ratio |  Volatility | Max Drawdown |  Calmar Ratio | Sortino Ratio |\n",
      "+---------------+---------------------+---------------+-------------+-------------+--------------+---------------+---------------+\n",
      "|  475.522062%  |     9163.965276%    | -8688.443214% |   0.000170  | 7490.473662 |   1.152787   | 128170.451527 |    0.435153   |\n",
      "+---------------+---------------------+---------------+-------------+-------------+--------------+---------------+---------------+\n",
      "metric result saved to metric_train_-1_agent_-1.pickle\n",
      "Valid Episode: [1/20]\n",
      "+---------------+---------------------+---------------+-------------+-------------+--------------+--------------+---------------+\n",
      "| Profit Margin | Buy and Hold Profit | Excess Profit | Sharp Ratio |  Volatility | Max Drawdown | Calmar Ratio | Sortino Ratio |\n",
      "+---------------+---------------------+---------------+-------------+-------------+--------------+--------------+---------------+\n",
      "|   28.159220%  |      30.951322%     |   -2.792102%  |   0.003394  | 1691.527853 |   0.353170   | 79856.144474 |    1.203946   |\n",
      "+---------------+---------------------+---------------+-------------+-------------+--------------+--------------+---------------+\n",
      "metric result saved to metric_valid_-1_agent_-1.pickle\n",
      "Valid Episode Reward Sum: 45784.267420\n",
      "save path /home/cqzong/TradeMaster/work_dir/algorithmic_trading_BTC_dqn_dqn_adam_mse/checkpoints/checkpoint-00001.pth\n",
      "Train Episode: [2/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-02-24 03:37:49,706]\u001b[0m Trial 0 failed with parameters: {'lr': 0.0005371032178814098, 'explore_rate': 0.25, 'hidden_nodes': (64, 32)} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cqzong/anaconda3/envs/trademaster/lib/python3.7/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_4125726/1660483780.py\", line 5, in objective\n",
      "    valid_score = trainer.train_and_valid_trial(sampled_params['trial_number'])\n",
      "  File \"/home/cqzong/TradeMaster/trademaster/trainers/algorithmic_trading/trainer.py\", line 214, in train_and_valid_trial\n",
      "    logging_tuple = self.agent.update_net(buffer)\n",
      "  File \"/home/cqzong/TradeMaster/trademaster/agents/algorithmic_trading/dqn.py\", line 152, in update_net\n",
      "    obj_critic, q_value = self.get_obj_critic(buffer, self.batch_size)\n",
      "  File \"/home/cqzong/TradeMaster/trademaster/agents/algorithmic_trading/dqn.py\", line 120, in get_obj_critic\n",
      "    with torch.no_grad():\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-02-24 03:37:49,710]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4125726/2358517618.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best trial:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trademaster/lib/python3.7/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         )\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trademaster/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trademaster/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trademaster/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trademaster/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4125726/1660483780.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msampled_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dqn_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mvalid_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_valid_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trial_number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalid_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TradeMaster/trademaster/trainers/algorithmic_trading/trainer.py\u001b[0m in \u001b[0;36mtrain_and_valid_trial\u001b[0;34m(self, trial_number)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0mlogging_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TradeMaster/trademaster/agents/algorithmic_trading/dqn.py\u001b[0m in \u001b[0;36mupdate_net\u001b[0;34m(self, buffer)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mupdate_times\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mobj_critic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_obj_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0mobj_critics\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mobj_critic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mobj_actors\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mq_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TradeMaster/trademaster/agents/algorithmic_trading/dqn.py\u001b[0m in \u001b[0;36mget_obj_critic\u001b[0;34m(self, buffer, batch_size)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \"\"\"\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mtransition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "cfg = Config.fromfile(args.config)\n",
    "\n",
    "if args.task_name.startswith(\"train\"):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=args.n_trials)\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "    print(\"  Best trial number: \", trial.number)\n",
    "    best_model_path = os.path.join(ROOT, cfg.work_dir, \"checkpoints\", \"trial-{:05d}.pth\".format(trial.number))\n",
    "    copyfile(best_model_path, os.path.join(ROOT, cfg.work_dir, \"checkpoints\", \"best.pth\"))\n",
    "    joblib.dump(study, os.path.join(ROOT, cfg.work_dir, \"auto_tuning.pkl\"))\n",
    "    trainer = test_dqn_builder(args, sampled_params = sample_params(study.best_trial))\n",
    "    trainer.test()\n",
    "    print(\"train end\")\n",
    "elif args.task_name.startswith(\"test\"):\n",
    "    study = joblib.load(os.path.join(ROOT, cfg.work_dir, \"auto_tuning.pkl\"))\n",
    "    trainer = test_dqn_builder(args, sampled_params = sample_params(study.best_trial))\n",
    "    trainer.test()\n",
    "    print(\"test end\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trademaster",
   "language": "python",
   "name": "trademaster"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
